NIKKEININJA ü•∑ - DOKUMENTACJA PROJEKTOWA
======================================

1. INFORMACJE PODSTAWOWE
-----------------------
Nazwa: NikkeiNinja
Wersja: 0.1.0
≈örodowisko: Windows 10 Pro
Framework: Python 3.11+
Trading Platform: MetaTrader 5

2. OPIS PROJEKTU
---------------
System automatycznego tradingu na JP225 (Nikkei), wykorzystujƒÖcy metodologiƒô Wyckoffa,
wspierany przez sztucznƒÖ inteligencjƒô i lokalny system RAG.

3. ≈öRODOWISKO DEWELOPERSKIE
--------------------------
- System: Windows 10 Pro (stabilniejszy ni≈º Win11)
- IDE: Cursor AI
- Model AI: claude-3-sonnet
- Python: 3.11+
- Git do wersjonowania

4. STRUKTURA PROJEKTU
--------------------
nikkeininja/
‚îú‚îÄ‚îÄ rdzen/              # G≈Ç√≥wne komponenty systemu
‚îÇ   ‚îú‚îÄ‚îÄ polaczenie_mt5.py
‚îÇ   ‚îú‚îÄ‚îÄ analiza_rynku.py
‚îÇ   ‚îî‚îÄ‚îÄ zarzadzanie_pozycjami.py
‚îú‚îÄ‚îÄ strategie/
‚îÇ   ‚îú‚îÄ‚îÄ wyckoff.py
‚îÇ   ‚îî‚îÄ‚îÄ rozpoznawanie_wzorcow.py
‚îú‚îÄ‚îÄ ai/
‚îÇ   ‚îú‚îÄ‚îÄ system_rag.py
‚îÇ   ‚îî‚îÄ‚îÄ uczenie_rynku.py
‚îú‚îÄ‚îÄ ryzyko/
‚îÇ   ‚îú‚îÄ‚îÄ zarzadzanie_ryzykiem.py
‚îÇ   ‚îî‚îÄ‚îÄ rozmiar_pozycji.py
‚îú‚îÄ‚îÄ narzedzia/
‚îÇ   ‚îú‚îÄ‚îÄ logowanie.py
‚îÇ   ‚îî‚îÄ‚îÄ konfiguracja.py
‚îú‚îÄ‚îÄ interfejs/
‚îÇ   ‚îú‚îÄ‚îÄ dashboard.py
‚îÇ   ‚îî‚îÄ‚îÄ kontrolki.py
‚îú‚îÄ‚îÄ testy/
‚îÇ   ‚îî‚îÄ‚îÄ test_rdzen.py
‚îî‚îÄ‚îÄ config/
    ‚îú‚îÄ‚îÄ ustawienia.yaml
    ‚îî‚îÄ‚îÄ logowanie.yaml

5. ZALE≈ªNO≈öCI (requirements.txt)
------------------------------
MetaTrader5==5.0.45
pandas==2.1.4
numpy==1.26.2
pytz==2023.3
python-dotenv==1.0.0
fastapi==0.109.0
uvicorn==0.27.0
chromadb==0.4.22
pydantic==2.5.3
pytest==7.4.4
pytest-asyncio==0.23.3
python-logging==0.4.9.6
PyYAML==6.0.1

6. G≈Å√ìWNE KOMPONENTY
-------------------
a) Integracja MT5
   - Po≈ÇƒÖczenie z platformƒÖ
   - Pobieranie danych
   - Wykonywanie zlece≈Ñ
   - ZarzƒÖdzanie kontem

b) Analiza Rynku
   - Implementacja Wyckoffa
   - Rozpoznawanie wzorc√≥w
   - Analiza wieloramkowa
   - Analiza wolumenu

c) System AI
   - Lokalny RAG
   - Uczenie siƒô wzorc√≥w
   - Adaptacja strategii
   - Analiza kontekstu

d) ZarzƒÖdzanie Ryzykiem
   - Sizing pozycji
   - Stop-loss
   - Take-profit
   - Trailing stop

7. KONWENCJE KODU
----------------
- Jƒôzyk: Polski w nazwach
- Asyncio dla operacji asynchronicznych
- Type hints
- Docstringi
- Obs≈Çuga b≈Çƒôd√≥w
- Logowanie

8. PRZYK≈ÅADOWA STRUKTURA KLASY
-----------------------------
```python
class KomponentNinja:
    """Bazowy szablon komponentu systemu NikkeiNinja."""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.config = self._wczytaj_config()
        
    async def inicjalizuj(self) -> Dict[str, Any]:
        """Inicjalizacja komponentu z walidacjƒÖ."""
        try:
            return {'sukces': True, 'komunikat': 'Komponent zainicjalizowany'}
        except Exception as e:
            self.logger.error(f"B≈ÇƒÖd inicjalizacji: {str(e)}")
            return {'sukces': False, 'b≈ÇƒÖd': str(e)}

9. KONWENCJE COMMIT√ìW
nowa: Nowa funkcjonalno≈õƒá
popr: Poprawka b≈Çƒôdu
dok: Dokumentacja
styl: Formatowanie
ref: Refaktoryzacja
test: Testy
admin: Administracja

10. KONFIGURACJA ≈öRODOWISKA
# Tworzenie ≈õrodowiska
python -m venv venv

# Aktywacja (Windows)
venv\Scripts\activate

# Instalacja zale≈ºno≈õci
pip install -r requirements.txt

11. PLIKI KONFIGURACYJNE
.env:

MT5_LOGIN=login
MT5_PASSWORD=haslo
MT5_SERVER=server
DEBUG=True

ustawienia.yaml:

system:
  nazwa: "NikkeiNinja"
  wersja: "0.1.0"
  debug: true

trading:
  symbol: "JP225"
  timeframes: ["M1", "M5", "M15", "H1"]
  max_pozycji: 3
  
ryzyko:
  max_ryzyko_trade: 0.02
  max_ryzyko_dzienne: 0.06

12. WYMAGANIA SPRZƒòTOWE
Procesor: Intel Core i5 lub lepszy
RAM: 16GB (minimum)
Dysk: SSD 128GB (minimum)
System: Windows 10 Pro

13. KOLEJNE KROKI
Konfiguracja ≈õrodowiska
Implementacja po≈ÇƒÖczenia z MT5
Podstawowa analiza danych
System zarzƒÖdzania ryzykiem
Implementacja Wyckoffa
System RAG
Interface u≈ºytkownika

14. ANALIZA SOCIAL MEDIA

### 14.1 Integracja z snscrape

System wykorzystuje bibliotekƒô snscrape do monitorowania medi√≥w spo≈Çeczno≈õciowych w poszukiwaniu wzmianek o Nikkei225. G≈Ç√≥wne funkcje:

- Asynchroniczne pobieranie danych z Twitter/X i LinkedIn
- Analiza sentymentu wypowiedzi
- System alert√≥w dla istotnych wzmianek
- Integracja z systemem RAG do adaptacji strategii

### 14.2 Monitorowane ≈∫r√≥d≈Ça

#### Twitter/X
- Hashtagi: #Nikkei225, #NikkeiIndex, #JapanStocks
- Kluczowe s≈Çowa: "Nikkei 225", "Japanese market"
- Wp≈Çywowi analitycy i traderzy

#### LinkedIn
- Posty ekspert√≥w rynkowych
- Analizy firm inwestycyjnych
- Raporty makroekonomiczne

### 14.3 Konfiguracja scrapera

```yaml
scraper_social:
  twitter:
    limit_wzmianek: 100
    interval_aktualizacji: 300  # sekundy
    min_followers: 1000
  linkedin:
    limit_wzmianek: 50
    interval_aktualizacji: 600
  alerty:
    prog_istotnosci: 0.8
    prog_sentymentu: 0.6
  rag:
    prog_istotnosci: 0.7
```

### 14.4 Wykorzystanie danych

1. Analiza sentymentu rynku
   - Ocena nastroj√≥w inwestor√≥w
   - Identyfikacja punkt√≥w zwrotnych
   - Wykrywanie skrajnych emocji

2. Adaptacja strategii
   - Dostosowanie parametr√≥w na podstawie sentymentu
   - Korelacja z analizƒÖ technicznƒÖ
   - Walidacja sygna≈Ç√≥w

3. System alert√≥w
   - Powiadomienia o istotnych wzmiankach
   - Monitoring wp≈Çywowych opinii
   - Ostrze≈ºenia o potencjalnych zagro≈ºeniach

### 14.5 Integracja z RAG

System RAG wykorzystuje dane z medi√≥w spo≈Çeczno≈õciowych do:

1. Wzbogacania bazy wiedzy
   - Nowe wzorce rynkowe
   - Korelacje sentymentu z ruchami cen
   - Identyfikacja kluczowych wydarze≈Ñ

2. Adaptacji strategii
   - Dostosowanie parametr√≥w na podstawie sentymentu
   - Walidacja sygna≈Ç√≥w technicznych
   - Optymalizacja moment√≥w wej≈õcia/wyj≈õcia

### 14.6 Przyk≈Çady u≈ºycia

```python
from narzedzia.scraper_social import ScraperSocial

# Inicjalizacja scrapera
scraper = ScraperSocial(config=config)

# Pobieranie wzmianek
wzmianki = await scraper.pobierz_wzmianki('twitter', 'Nikkei225')

# Monitorowanie w czasie rzeczywistym
await scraper.monitoruj_wzmianki('Nikkei225 OR Japanese market')

# Eksport danych
scraper.eksportuj_do_csv('wzmianki.csv')
```

### 14.7 Obs≈Çuga b≈Çƒôd√≥w i limit√≥w

1. Limity API
   - Automatyczne przestrzeganie limit√≥w
   - Kolejkowanie zapyta≈Ñ
   - Cache wynik√≥w

2. Obs≈Çuga b≈Çƒôd√≥w
   - Retry dla b≈Çƒôd√≥w sieciowych
   - Logowanie problem√≥w
   - Graceful degradation

3. Walidacja danych
   - Filtrowanie spamu
   - Weryfikacja ≈∫r√≥de≈Ç
   - Kontrola jako≈õci

## NARZƒòDZIA

### ScraperSocial

Modu≈Ç do monitorowania i analizy wzmianek w mediach spo≈Çeczno≈õciowych.

#### G≈Ç√≥wne funkcje:
- Asynchroniczne pobieranie danych z Twitter/X i LinkedIn
- Analiza sentymentu wypowiedzi
- System alert√≥w dla istotnych wzmianek
- Integracja z systemem RAG

#### Integracja z komponentami:
- SystemRAG: Wzbogacanie bazy wiedzy o dane z social media
- AnalizaRynku: Korelacja sentymentu z ruchami cen
- ZarzadzanieRyzykiem: Dostosowanie parametr√≥w na podstawie nastroj√≥w

#### Przyk≈Çad konfiguracji:

```yaml
narzedzia:
  scraper_social:
    twitter:
      limit_wzmianek: 100
      interval_aktualizacji: 300
    linkedin:
      limit_wzmianek: 50
      interval_aktualizacji: 600
    alerty:
      prog_istotnosci: 0.8
    rag:
      prog_istotnosci: 0.7
```